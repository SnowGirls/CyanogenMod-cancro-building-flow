
git clone https://github.com/ios-control/ios-deploy.git
cd ios-deploy/ 
git checkout 1.12.1

## build it. -workspace <workspacename> or -project <projectname>
xcodebuild -project ios-deploy.xcodeproj -list
xcodebuild -project ios-deploy.xcodeproj -scheme ios-deploy

## get the built output path
xcodebuild -project ios-deploy.xcodeproj -scheme ios-deploy -showBuildSettings | grep BUILD_DIR


## ios-deploy --verbose --id 00008020-001B048A0EF0402E --debug --justlaunch --noinstall --bundle ~/Workspaces/FlutterProject/build/ios/iphoneos/Runner.app









##### 如何调试 Podfile

https://stackoverflow.com/a/52773670/1749293
https://medium.com/@GalvinLi/tinysolution-cocoapods%E7%B1%BB%E9%87%8D%E5%A4%8D%E5%AE%9E%E7%8E%B0%E8%AD%A6%E5%91%8A%E5%A4%84%E7%90%86-ba88bb3deaf6


IDE 用 RubyMine

1. 用 RubyMine 打开一个 支持了 Cocoaspod XCode 工程的目录，如拿 Github TinySolution [https://github.com/bestwnh/TinySolution.git] 为例子

	Edit Configuration -> Add + -> Ruby -> Ruby script: /usr/local/bin/pod, Script arguments: install -> Working directory: /__path_to__/TinySolution -> Ruby SDK: set it as in [Ruby script]

2. ln -s Podfile Podfile.rb

3. 双击打开 Podfile.rb , 设置断点

4. 点击 Debug






### 先扔这里了
---------------------------------  为什么cpu的浮点计算能力差，什么是浮点计算，gpu为什么擅长浮点计算？  ---------------------------------
REF: 为什么cpu的浮点计算能力差，什么是浮点计算，gpu为什么擅长浮点计算？ - 三銓三的回答 - 知乎 https://www.zhihu.com/question/296192765/answer/503056553

浮点是什么？其他答主说了是小数点的数字，这个没错但是关键区别在于它的格式。普通整数的表达方式很简单，就是二进制

的同一个数字而已，1是1，2是10，3是11，4是100之类的。但是计算机里如何表示小数点？

所谓浮点最重要的区别就是它是用科学计数法

的，一个浮点数字被分为两半，其中一半记录一个数字，另一半记录10的多少次方。比如1.56424你可以写成：

156424乘以10的-5次方

这样你就把一个小数变成了两个整数，但是其中一个是负数，电脑怎么表示负数？这个也简单，比如说总共只有4位数，可以表达0-9999，你可以把它分为两半，定义其中4999表示0，4998表示-1，5000表示+1等等。这样你就可以表达-4999到+4999了。

还是刚才的小数1.56424，我就可以把它写成两个整数：

156424，4994
这就是电脑里的浮点数

很明显当我要相加这样的两个数字，程序和直接相加两个整数是完全不同的，因为其中一部分是次方数，次方数不同的两个数字不能相加，相同的相加出来的结果也可能影响次方数等等问题。当然你可以写一个软件进行各种换算让cpu的基本整数运算电路来算浮点，但是这样很慢。更好的办法是直接在处理器里设置算浮点的电路，这就是现代cpu里的fpu。

再看看刚才我们举例的这个浮点数：

156424，4994

由于cpu的电路设计
是基于位宽的，就是说这个数据有多少位数字，比如上面这个就是12位，实际上我们写浮点数字

的时候是有固定长度的。

比如我们这个数字代表的小数是1.56424，在同样格式的情况下我是无法表达1.56424739的，多余出来的位数只能直接丢掉。
这也就是说浮点数据不是完全准确的，而是近似值

如果你用基本的浮点指令
去计算10除以3再乘以3，它会告诉你是9.99999999。这就是因为浮点数据的有损特性

。

要缓解这个精度问题，只能提高位数，比如12位的浮点格式我给你改成20位。但是要一次计算20位长度的浮点，你就需要更宽，更复杂的电路。

实际使用的单精度浮点

是32位，双精度是64位。

英特尔的cpu计算浮点的时候内部精度是80位，输出输入还是64位。显卡很多都是单精度32位的，就算支持64位的话速度一般会尿崩。专业计算卡

现在一般都是64位。

所以说第一个问题就是复杂程度，cpu的fpu率先支持了更高宽度的数据，电路更复杂。而显卡一直以来都是在用单精度浮点，很多根本没法执行双精度运算。

第二个问题就是cpu的fpu
是和逻辑单元同步的，这样可以保证编程方面的兼容性，因为以前的机器一直是这么搞的，老传统了。核心数量和频率都是同步的，每个fpu必须配对全套的逻辑，解码单元

等等。所以说你cpu只能几个核心。但是既然反正核心就那么几个，我就可以把它做得异常强大，支持各种最宽的数据格式，可以用更少的步骤做三角函数，除法，开方之类的计算。

而相比之下显卡基本就是大批大批的小型fpu，其他的东西能少就少。

如果你只做一道浮点运算
，其实是cpu更快，而且可以块非常多。但问题是通常来说浮点运算都是大批量的作，而且互相之间没有关联，一道题的结果和下一题的结果很少有关联。这种情况下大批大批的小型fpu就有优势了
---------------------------------  为什么cpu的浮点计算能力差，什么是浮点计算，gpu为什么擅长浮点计算？  ---------------------------------





